{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern, DotProduct\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy import optimize\n",
    "\n",
    "import arviz as az\n",
    "from arviz.utils import Numba\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as t\n",
    "from scipy.stats import gaussian_kde\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "OUTPUT_PATH = \"./Results\"\n",
    "\n",
    "from data_loading import LoadData\n",
    "from proj_consts import ProjectConsts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataset(xdata, ydata, xlabel, ylabel, figname, data_type):\n",
    "    f = plt.figure(figsize=(9, 7))\n",
    "\n",
    "    plt.plot(\n",
    "        xdata,\n",
    "        ydata,\n",
    "        marker=\"o\",\n",
    "        linestyle=\"\",\n",
    "    )\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"{OUTPUT_PATH}/\" + figname + \"_\" + str(data_type) + \".pdf\")\n",
    "\n",
    "    \n",
    "def plotDatasetsComparison(xdata, ydata1, ydata2, leg1, leg2, xlabel, ylabel, figname):\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "    plt.plot(\n",
    "        xdata,\n",
    "        ydata1,\n",
    "        label=leg1,\n",
    "        marker=\"o\",\n",
    "        markersize=0,\n",
    "        linestyle=\"-\",\n",
    "        linewidth=1.0,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        xdata,\n",
    "        ydata2,\n",
    "        label=leg2,\n",
    "        marker=\"o\",\n",
    "        markersize=0,\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig(f\"{OUTPUT_PATH}/\" + figname + \".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_confirmed = 5\n",
    "num_days_data = 210\n",
    "\n",
    "df_brazil_state_cases = LoadData.getBrazilDataFrame(min_confirmed)\n",
    "rj_state_cases = LoadData.getBrazilStateDataFrame(df_brazil_state_cases, \"RJ\")\n",
    "rj_state_cases = rj_state_cases.head(num_days_data)\n",
    "print(rj_state_cases)\n",
    "\n",
    "target_population = ProjectConsts.RJ_STATE_POPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time = rj_state_cases.day.values.astype(np.float64)\n",
    "\n",
    "dead_individuals = rj_state_cases.dead.values\n",
    "infected_individuals = rj_state_cases.infected.values\n",
    "confirmed_cases = rj_state_cases.confirmed.values\n",
    "recovered_cases = rj_state_cases.recovered.values\n",
    "\n",
    "original_data = [dead_individuals, infected_individuals, confirmed_cases, recovered_cases]\n",
    "original_data_reg = np.zeros((4, len(data_time)))\n",
    "\n",
    "for i, data in enumerate(original_data):\n",
    "    scale_factor = data[-1] / 100\n",
    "    data = data / scale_factor\n",
    "\n",
    "    # Defining the kernel\n",
    "    if i == 1: # When dealing with new confirmed cases dataset\n",
    "        kernel = Matern()\n",
    "    else:\n",
    "        kernel = ConstantKernel() * Matern() + DotProduct()\n",
    "\n",
    "    # Creating GP regressor\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=50, alpha=10, normalize_y=False)\n",
    "\n",
    "    # Training the model\n",
    "    model.fit(data_time.reshape(-1, 1), data)\n",
    "\n",
    "    # Results\n",
    "    target_pred = model.predict(data_time.reshape(-1, 1), return_std=False)\n",
    "\n",
    "    original_data_reg[i] = target_pred * scale_factor\n",
    "    \n",
    "    print(\"\\nLearned kernel: %s\" % model.kernel_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing original and regularized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, (data, data_reg) in enumerate(zip(original_data, original_data_reg)):\n",
    "    if k == 0:\n",
    "        legend1 = \"Dead individuals (cumulative)\";\n",
    "    elif k == 1:\n",
    "        legend1 = \"New confirmed cases\";\n",
    "    elif k == 2:\n",
    "        legend1 = \"Infected individuals (cumulative)\";\n",
    "    else:\n",
    "        legend1 = \"Recovered individuals (cumulative)\";\n",
    "        \n",
    "    plotDatasetsComparison(\n",
    "        data_time,\n",
    "        data,\n",
    "        data_reg,\n",
    "        legend1,\n",
    "        \"Regularized data\",\n",
    "        \"Time (days)\",\n",
    "        \"Population\",\n",
    "        legend1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining SEIRPDQ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def seirpdq_model(\n",
    "    t,\n",
    "    X,\n",
    "    beta,\n",
    "    gamma_I,\n",
    "    gamma_P,\n",
    "    d_P,\n",
    "    omega,\n",
    "    rho,\n",
    "    sigma,\n",
    "    N=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    SEIRPD-Q python implementation.\n",
    "    \"\"\"\n",
    "    S, E, I, P, R, D, C, H = X\n",
    "    S_prime = -beta / N * S * I - omega * S\n",
    "    E_prime = beta / N * S * I - sigma * E - omega * E\n",
    "    I_prime = sigma * rho * E - gamma_I * I - omega * I\n",
    "    P_prime = sigma * (1 - rho) * E - d_P * P - gamma_P * P\n",
    "    R_prime = gamma_I * I + gamma_P * P + omega * (S + E + I)\n",
    "    D_prime = d_P * P\n",
    "    C_prime = sigma * (1 - rho) * E\n",
    "    H_prime = gamma_P * P\n",
    "    return S_prime, E_prime, I_prime, P_prime, R_prime, D_prime, C_prime, H_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the ODE solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seirpdq_ode_solver(\n",
    "    y0,\n",
    "    t_span,\n",
    "    t_eval,\n",
    "    beta,\n",
    "    omega,\n",
    "    d_P,\n",
    "    gamma_P=1 / 16.7,\n",
    "    gamma_I=1 / 16.7,\n",
    "    rho=0.6,\n",
    "    sigma=1 / 5.8,\n",
    "    N=1,\n",
    "):\n",
    "    solution_ODE = solve_ivp(\n",
    "        fun=lambda t, y: seirpdq_model(\n",
    "            t,\n",
    "            y,\n",
    "            beta=beta,\n",
    "            gamma_I=gamma_I,\n",
    "            gamma_P=gamma_P,\n",
    "            d_P=d_P,\n",
    "            omega=omega,\n",
    "            rho=rho,\n",
    "            sigma=sigma,\n",
    "            N=N,\n",
    "        ),\n",
    "        t_span=t_span,\n",
    "        y0=y0,\n",
    "        t_eval=t_eval,\n",
    "        method=\"LSODA\",\n",
    "    )\n",
    "\n",
    "    return solution_ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining problem wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seirpdq_least_squares_error_ode_y0(\n",
    "    par, time_exp, f_exp, fitting_model, known_initial_conditions, total_population\n",
    "):\n",
    "    num_of_initial_conditions_to_fit = 1\n",
    "    num_of_parameters = len(par) - num_of_initial_conditions_to_fit\n",
    "    args, trial_initial_conditions = [\n",
    "        par[:num_of_parameters],\n",
    "        par[num_of_parameters:],\n",
    "    ]\n",
    "    E0 = trial_initial_conditions\n",
    "    I0, P0, R0, D0, C0, H0 = known_initial_conditions\n",
    "    S0 = total_population - (E0 + I0 + P0 + R0 + D0)\n",
    "    initial_conditions = [S0, E0, I0, P0, R0, D0, C0, H0]\n",
    "\n",
    "    f_exp1, f_exp2, f_exp3, f_exp4 = f_exp\n",
    "    time_span = (time_exp.min(), time_exp.max())\n",
    "\n",
    "    num_of_qoi = len(f_exp1)\n",
    "\n",
    "    try:\n",
    "        y_model = fitting_model(initial_conditions, time_span, time_exp, *args)\n",
    "        simulated_time = y_model.t\n",
    "        \n",
    "        # dead_individuals, infected_individuals, confirmed_cases, recovered_cases\n",
    "        simulated_ode_solution = y_model.y\n",
    "        (\n",
    "            _,\n",
    "            _,\n",
    "            simulated_qoi2,\n",
    "            _,\n",
    "            simulated_qoi4,\n",
    "            simulated_qoi1,\n",
    "            simulated_qoi3,\n",
    "            _,\n",
    "        ) = simulated_ode_solution\n",
    "\n",
    "        residual1 = f_exp1 - simulated_qoi1  # Deaths (cumulative)\n",
    "        residual2 = f_exp2 - simulated_qoi2  # Infected\n",
    "        residual3 = f_exp3 - simulated_qoi3  # Cases (cumulative)\n",
    "        residual4 = f_exp4 - simulated_qoi4  # Recovered (cumulative)\n",
    "\n",
    "        # Watch out the weights\n",
    "        first_term = 1.0 * np.sum(residual1 ** 2.0)\n",
    "        second_term = 0.0 * np.sum(residual2 ** 2.0)\n",
    "        third_term = 1.0 * np.sum(residual3 ** 2.0)\n",
    "        fourth_term = 0.0 * np.sum(residual4 ** 2.0)\n",
    "        \n",
    "        objective_function = 1 / num_of_qoi * (first_term + second_term + third_term + fourth_term)\n",
    "    except ValueError:\n",
    "        objective_function = 1e15\n",
    "\n",
    "    return objective_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the number of days for validation and calibration data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days_prediction = 7\n",
    "\n",
    "data_type = \"reg\" # \"original\" or \"reg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining calibration/validation ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_calibration_data = 60\n",
    "max_calibration_data = len(data_time) - num_days_prediction\n",
    "step_calibration_data = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the number of problems to be solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = int(((max_calibration_data - min_calibration_data - 1) / step_calibration_data) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time = np.array(data_time) # Casting time data to numpy array\n",
    "\n",
    "original_data = np.array(original_data) # Casting original data to numpy array\n",
    "\n",
    "original_data_reg = np.array(original_data_reg) # Casting regularized data to numpy array\n",
    "original_data_reg[np.where(original_data_reg < 0)] = 0 # Avoiding negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting known initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I0, P0, R0, D0, C0, H0 = (\n",
    "    int(float(confirmed_cases[0])),\n",
    "    int(float(confirmed_cases[0])),\n",
    "    int(float(recovered_cases[0])),\n",
    "    int(float(dead_individuals[0])),\n",
    "    int(float(confirmed_cases[0])),\n",
    "    int(float(recovered_cases[0])),\n",
    ")\n",
    "y0_seirpdq = I0, P0, R0, D0, C0, H0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_model(data_time, y0, pars):\n",
    "    S0 = target_population - (pars[3] + y0[0] + y0[1] + y0[2] + y0[3])\n",
    "    y0_sol = S0, pars[3], y0[0], y0[1], y0[2], y0[3], y0[4], y0[5]\n",
    "\n",
    "    t0 = float(data_time.min())\n",
    "    tf = float(data_time.max())\n",
    "\n",
    "    solution_ODE = seirpdq_ode_solver(\n",
    "        y0_sol, (t0, tf), data_time, pars[0], pars[1], pars[2]\n",
    "    )\n",
    "\n",
    "    t_solution_ODE, y_solution_ODE = (\n",
    "        solution_ODE.t,\n",
    "        solution_ODE.y,\n",
    "    )\n",
    "    \n",
    "    return y_solution_ODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining optimization algorithm search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_seirpdq = [\n",
    "    (0, 1e-6),   # beta\n",
    "    (0, 0.025),  # omega\n",
    "    (0, 0.025),  # d_P\n",
    "    (0, 10000),  # E0\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRMSE(data1, data2, num_days_prediction):\n",
    "    diff_dead = data1[0, :] - data2[0, :]\n",
    "    diff_infected = data1[1, :] - data2[1, :]\n",
    "    diff_confirmed = data1[2, :] - data2[2, :]\n",
    "    diff_recovered = data1[3, :] - data2[3, :]\n",
    "    \n",
    "    dead_residual = np.sqrt(np.power(np.sum(diff_dead), 2) / num_days_prediction)\n",
    "    infected_residual = np.sqrt(np.power(np.sum(diff_infected), 2) / num_days_prediction) # Not used\n",
    "    confirmed_residual = np.sqrt(np.power(np.sum(diff_confirmed), 2) / num_days_prediction)\n",
    "    recovered_residual = np.sqrt(np.power(np.sum(diff_recovered), 2) / num_days_prediction) # Not used\n",
    "    \n",
    "    rmse = dead_residual + confirmed_residual\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing arrays to store results (original data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_values = np.zeros(n_runs)\n",
    "omega_values = np.zeros(n_runs)\n",
    "d_P_values = np.zeros(n_runs)\n",
    "E0_values = np.zeros(n_runs)\n",
    "RMSE_values = np.zeros(n_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the problem n_runs times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([3.2695e-8, 0.0137886, 0.0125293, 415.8004]) # This is know by prior executions (can also be random)\n",
    "bounds = bounds_seirpdq\n",
    "\n",
    "for p, num_data_calibration in enumerate(np.arange(min_calibration_data, max_calibration_data, step_calibration_data)):\n",
    "    data_time_validation = data_time[num_data_calibration : (num_data_calibration + num_days_prediction)]\n",
    "    validation_data = original_data[:, num_data_calibration : (num_data_calibration + num_days_prediction)]\n",
    "    \n",
    "    data_time_calibration = data_time[0 : num_data_calibration]\n",
    "    if data_type == \"original\":\n",
    "        calibration_data = original_data[:, 0 : num_data_calibration] # Using original data\n",
    "    elif data_type == \"reg\":\n",
    "        calibration_data = original_data_reg[:, 0 : num_data_calibration] # Using regularized dataset\n",
    "    \n",
    "    print(\"\\nRun: %d/%d\\n\" %(p+1, n_runs))\n",
    "    \n",
    "    success_res = False\n",
    "    \n",
    "    while success_res == False:\n",
    "        \n",
    "        print(x0)\n",
    "    \n",
    "        result_NM = optimize.minimize(\n",
    "            seirpdq_least_squares_error_ode_y0,\n",
    "            x0=x0,\n",
    "            args=(\n",
    "                data_time_calibration,\n",
    "                calibration_data,\n",
    "                seirpdq_ode_solver,\n",
    "                y0_seirpdq,\n",
    "                target_population,\n",
    "            ),\n",
    "            method=\"Nelder-Mead\",\n",
    "            options={\"maxiter\": 500},\n",
    "        )  \n",
    "        \n",
    "        if result_NM.success == True:\n",
    "            sol_NM = result_NM.x\n",
    "            for k in range(len(x0)):\n",
    "                bounds[k] = (sol_NM[k] - 0.05 * sol_NM[k], sol_NM[k] + 0.05 * sol_NM[k])\n",
    "        \n",
    "            result_DE = optimize.differential_evolution(\n",
    "                seirpdq_least_squares_error_ode_y0,\n",
    "                bounds=bounds,\n",
    "                args=(\n",
    "                    data_time_calibration,\n",
    "                    calibration_data,\n",
    "                    seirpdq_ode_solver,\n",
    "                    y0_seirpdq,\n",
    "                    target_population,\n",
    "                ),\n",
    "                popsize=20,\n",
    "                strategy=\"best1bin\",\n",
    "                tol=1e-6,\n",
    "                recombination=0.95,\n",
    "                mutation=0.6,\n",
    "                maxiter=1000,\n",
    "                polish=True,\n",
    "                init=\"latinhypercube\",\n",
    "                disp=False,\n",
    "                seed=seed,\n",
    "                callback=None,\n",
    "                updating=\"immediate\",\n",
    "                workers=1,\n",
    "            )\n",
    "            success_res = result_DE.success\n",
    "        \n",
    "        else:\n",
    "            for i in range(len(bounds_seirpdq)):\n",
    "                sign = np.random.uniform(0, 0.01, 1)\n",
    "                shift = sign * x0[i]\n",
    "\n",
    "                if np.random.uniform(0, 1, 1) < 0.5:\n",
    "                    x0[i] = x0[i] - shift\n",
    "                else:\n",
    "                    x0[i] = x0[i] + shift\n",
    "\n",
    "    print(result_DE)\n",
    "    \n",
    "    opt_pars = result_DE.x\n",
    "    (\n",
    "        beta_deterministic,\n",
    "        omega_deterministic,\n",
    "        d_P_deterministic,\n",
    "        E0_deterministic\n",
    "    ) = opt_pars\n",
    "\n",
    "    beta_values[p] = beta_deterministic\n",
    "    omega_values[p] = omega_deterministic\n",
    "    d_P_values[p] = d_P_deterministic\n",
    "    E0_values[p] = E0_deterministic\n",
    "\n",
    "    y_solution_ODE = simulate_model(data_time, y0_seirpdq, opt_pars)\n",
    "    \n",
    "    (\n",
    "        S_predict_seirpdq,\n",
    "        E_predict_seirpdq,\n",
    "        I_predict_seirpdq,\n",
    "        P_predict_seirpdq,\n",
    "        R_predict_seirpdq,\n",
    "        D_predict_seirpdq,\n",
    "        C_predict_seirpdq,\n",
    "        H_predict_seirpdq,\n",
    "    ) = y_solution_ODE\n",
    "\n",
    "    validation_results = np.vstack((D_predict_seirpdq, I_predict_seirpdq, C_predict_seirpdq, R_predict_seirpdq))\n",
    "    validation_results = validation_results[:, num_data_calibration : (num_data_calibration + num_days_prediction)]\n",
    "\n",
    "    RMSE_values[p] = calcRMSE(validation_data, validation_results, num_days_prediction)\n",
    "    \n",
    "    x0 = opt_pars\n",
    "    for i in range(len(bounds_seirpdq)):\n",
    "        sign = np.random.uniform(0, 0.01, 1)\n",
    "        shift = sign * x0[i]\n",
    "\n",
    "        if np.random.uniform(0, 1, 1) < 0.5:\n",
    "            x0[i] = x0[i] - shift\n",
    "        else:\n",
    "            x0[i] = x0[i] + shift\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving optimal parameter values to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(beta_values).to_csv(f\"{OUTPUT_PATH}/beta_{data_type}.csv\")\n",
    "pd.DataFrame(omega_values).to_csv(f\"{OUTPUT_PATH}/omega_{data_type}.csv\")\n",
    "pd.DataFrame(d_P_values).to_csv(f\"{OUTPUT_PATH}/d_P_{data_type}.csv\")\n",
    "pd.DataFrame(E0_values).to_csv(f\"{OUTPUT_PATH}/E0_{data_type}.csv\")\n",
    "pd.DataFrame(RMSE_values).to_csv(f\"{OUTPUT_PATH}/RMSE_{data_type}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting optimal parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array_n_runs = np.linspace(1, n_runs, num=n_runs)\n",
    "\n",
    "plotDataset(array_n_runs, beta_values, \"Run\", \"beta\", \"beta\", data_type)\n",
    "plotDataset(array_n_runs, omega_values, \"Run\", \"omega\", \"omega\", data_type)\n",
    "plotDataset(array_n_runs, d_P_values, \"Run\", \"d_P\", \"d_P\", data_type)\n",
    "plotDataset(array_n_runs, E0_values, \"Run\", \"E0\", \"E0\", data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing values of RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_values = pd.read_csv(f\"{OUTPUT_PATH}/RMSE_original.csv\", sep=',', usecols=[1]).to_numpy()\n",
    "RMSE_values_reg = pd.read_csv(f\"{OUTPUT_PATH}/RMSE_reg.csv\", sep=',', usecols=[1]).to_numpy()\n",
    "\n",
    "array_n_runs = np.linspace(1, n_runs, num=n_runs)\n",
    "\n",
    "plotDatasetsComparison(\n",
    "    array_n_runs,\n",
    "    RMSE_values,\n",
    "    RMSE_values_reg,\n",
    "    \"Original data\",\n",
    "    \"Regularized data\",\n",
    "    \"Run\",\n",
    "    \"RMSE\",\n",
    "    \"RMSE_original_reg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE (original data) = %f\\n\" %(np.mean(RMSE_values)))\n",
    "print(\"RMSE (regularized data) = %f\" %(np.mean(RMSE_values_reg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation of infected curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols_confirmed = np.zeros((int(array_n_runs[-1]), int(data_time[-1] - min_confirmed + 1)))\n",
    "sols_dead = np.zeros((int(array_n_runs[-1]), int(data_time[-1] - min_confirmed + 1)))\n",
    "\n",
    "for p in np.array(array_n_runs, dtype=np.int):\n",
    "    parameters = [beta_values[p - 1], omega_values[p - 1], d_P_values[p - 1]]\n",
    "    \n",
    "    S0 = target_population - (E0_values[p - 1] + I0 + P0 + R0 + D0)\n",
    "    y0_sol = S0, E0_values[p - 1], I0, P0, R0, D0, C0, H0\n",
    "    \n",
    "    t0 = float(data_time.min())\n",
    "    tf = float(data_time.max())\n",
    "    \n",
    "    solution_ODE = seirpdq_ode_solver(\n",
    "        y0_sol, (t0, tf), data_time, *parameters\n",
    "    )\n",
    "    \n",
    "    t_solution_ODE, y_solution_ODE = (\n",
    "        solution_ODE.t,\n",
    "        solution_ODE.y,\n",
    "    )\n",
    "    \n",
    "    (\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        D_predict_seirpdq,\n",
    "        C_predict_seirpdq,\n",
    "        _,\n",
    "    ) = y_solution_ODE\n",
    "    \n",
    "    sols_confirmed[p - 1, :] = np.array((C_predict_seirpdq)).reshape((1, int(data_time[-1] - min_confirmed + 1)))\n",
    "    sols_dead[p - 1, :] = np.array((D_predict_seirpdq)).reshape((1, int(data_time[-1] - min_confirmed + 1)))\n",
    "\n",
    "pd.DataFrame(sols_confirmed).to_csv(f\"{OUTPUT_PATH}/{data_type}_sols_confirmed.csv\")\n",
    "pd.DataFrame(sols_dead).to_csv(f\"{OUTPUT_PATH}/{data_type}_sols_dead.csv\")\n",
    "    \n",
    "if data_type == \"original\":\n",
    "    confirmed_data = original_data[2, :]\n",
    "    dead_data = original_data[0, :]\n",
    "else:\n",
    "    confirmed_data = original_data_reg[2, :]\n",
    "    dead_data = original_data_reg[0, :]\n",
    "\n",
    "plotDatasetsComparison(\n",
    "    data_time,\n",
    "    sols_confirmed.T,\n",
    "    confirmed_data,\n",
    "    None,\n",
    "    \"Original data of confirmed individuals\",\n",
    "    \"Time (days)\",\n",
    "    \"Population\",\n",
    "    \"comparison_infected_cumulative_original\")\n",
    "\n",
    "plotDatasetsComparison(\n",
    "    data_time,\n",
    "    sols_dead.T,\n",
    "    dead_data,\n",
    "    None,\n",
    "    \"Original data of dead individuals\",\n",
    "    \"Time (days)\",\n",
    "    \"Population\",\n",
    "    \"comparison_dead_cumulative_original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sols_confirmed = pd.read_csv(f\"{OUTPUT_PATH}/original_sols_confirmed.csv\", sep=',', usecols=[1]).to_numpy()\n",
    "reg_sols_confirmed = pd.read_csv(f\"{OUTPUT_PATH}/reg_sols_confirmed.csv\", sep=',', usecols=[1]).to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "labels = ['Original data', 'Regularized data']\n",
    "data_sim_confirmed = np.array((np.vstack([original_sols_confirmed[:, -1], reg_sols_confirmed[:, -1]]))).T\n",
    "\n",
    "bplot2 = ax.boxplot(data_sim_confirmed,\n",
    "                     notch=True,  # notch shape\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                     labels=labels,\n",
    "                     whis=(0,100),)\n",
    "\n",
    "plt.plot([0.5, 2.5], [original_data[2, -1], original_data[2, -1]])\n",
    "\n",
    "plt.xlabel(\"Boxes\")\n",
    "plt.ylabel(\"Observed values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(f\"{OUTPUT_PATH}/box_plot_confirmed_simulations_line.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical results comparing variations on simulations using original and regularized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_sols_dead = pd.read_csv(f\"{OUTPUT_PATH}/original_sols_dead.csv\", sep=',', usecols=[1]).to_numpy()\n",
    "reg_sols_dead = pd.read_csv(f\"{OUTPUT_PATH}/reg_sols_dead.csv\", sep=',', usecols=[1]).to_numpy()\n",
    "\n",
    "print(\"Min predicted confirmed (regularized data): %d\" %int(np.min(reg_sols_confirmed[:, -1])))\n",
    "print(\"Max predicted confirmed (regularized data): %d\" %int(np.max(reg_sols_confirmed[:, -1])))\n",
    "\n",
    "print(\"Min predicted dead (regularized data): %d\" %int(np.min(reg_sols_dead[:, -1])))\n",
    "print(\"Max predicted dead (regularized data): %d\\n\" %int(np.max(reg_sols_dead[:, -1])))\n",
    "\n",
    "print(\"Min predicted confirmed (original data): %d\" %int(np.min(original_sols_confirmed[:, -1])))\n",
    "print(\"Max predicted confirmed (original data): %d\" %int(np.max(original_sols_confirmed[:, -1])))\n",
    "\n",
    "print(\"Min predicted dead (original data): %d\" %int(np.min(original_sols_dead[:, -1])))\n",
    "print(\"Max predicted dead (original data): %d\" %int(np.max(original_sols_dead[:, -1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Bayesian calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_data_fit = \"regularized_no_d_P\"\n",
    "num_data_calibration = 70\n",
    "\n",
    "data_time_calibration = data_time[0 : num_data_calibration]\n",
    "np_original_data = np.array(original_data)\n",
    "if bayes_data_fit == \"original\":\n",
    "    observations_to_fit = np.vstack([np_original_data[0, 0 : num_data_calibration], np_original_data[2, 0 : num_data_calibration]]).T\n",
    "elif bayes_data_fit == \"regularized_no_d_P\":\n",
    "    observations_to_fit = np.vstack([original_data_reg[0, 0 : num_data_calibration], original_data_reg[2, 0 : num_data_calibration]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ODE wrapper for bayesian calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@theano.compile.ops.as_op(\n",
    "    itypes=[\n",
    "        t.dvector,\n",
    "        t.dvector,\n",
    "        t.dscalar,\n",
    "        t.dscalar,  # beta\n",
    "        t.dscalar,  # omega\n",
    "        t.dscalar,  # d_P\n",
    "        t.dscalar,  # E0\n",
    "    ],\n",
    "    otypes=[t.dmatrix],\n",
    ")\n",
    "def seirpdq_ode_wrapper_with_y0(\n",
    "    time_exp, initial_conditions, total_population, beta, omega, d_P, E0\n",
    "):\n",
    "    time_span = (time_exp.min(), time_exp.max())\n",
    "    args = [beta, omega, d_P]\n",
    "\n",
    "    S0 = total_population - (\n",
    "        E0 + initial_conditions[0] + initial_conditions[1] + initial_conditions[2] + initial_conditions[3]\n",
    "    )\n",
    "    ICs = (\n",
    "        S0,\n",
    "        E0,\n",
    "        initial_conditions[0],  # I\n",
    "        initial_conditions[1],  # P\n",
    "        initial_conditions[2],  # R\n",
    "        initial_conditions[3],  # D\n",
    "        initial_conditions[4],  # C\n",
    "        initial_conditions[5],  # H\n",
    "    )\n",
    "\n",
    "    y_model = seirpdq_ode_solver(ICs, time_span, time_exp, *args)\n",
    "    simulated_time = y_model.t\n",
    "    simulated_ode_solution = y_model.y\n",
    "    (_, _, _, _, _, simulated_qoi1, simulated_qoi2, _,) = simulated_ode_solution\n",
    "\n",
    "    concatenate_simulated_qoi = np.vstack([simulated_qoi1, simulated_qoi2]).T\n",
    "\n",
    "    return concatenate_simulated_qoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Bayesian calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = 3000\n",
    "start_time = time.time()\n",
    "percent_calibration = 0.95\n",
    "\n",
    "y0_seirpdq = np.array([I0, P0, R0, D0, C0, H0], dtype=np.float64)\n",
    "\n",
    "with pm.Model() as model_mcmc:\n",
    "\n",
    "    beta = pm.Uniform(\n",
    "        \"beta\", \n",
    "        lower=0, \n",
    "        upper=1e-6,\n",
    "    )\n",
    "    omega = pm.Uniform(\n",
    "        \"omega\", \n",
    "        lower=0, \n",
    "        upper=0.02,\n",
    "    )\n",
    "    d_P = pm.Uniform(\n",
    "        \"d_P\",\n",
    "        lower=0,\n",
    "        upper=0.02,\n",
    "    )\n",
    "    E0_uncertain = pm.Uniform(\n",
    "        \"E0\",\n",
    "        lower=0,\n",
    "        upper=10000\n",
    "    )\n",
    "\n",
    "    standard_deviation = pm.Uniform(\n",
    "        \"std_deviation\",\n",
    "        lower=1e0,\n",
    "        upper=1e4,\n",
    "        shape=2\n",
    "    )\n",
    "\n",
    "    fitting_model = pm.Deterministic(\n",
    "        \"seirpdq_model\",\n",
    "        seirpdq_ode_wrapper_with_y0(\n",
    "            theano.shared(data_time_calibration),\n",
    "            theano.shared(np.array(y0_seirpdq)),\n",
    "            theano.shared(target_population),\n",
    "            beta,\n",
    "            omega,\n",
    "            d_P,\n",
    "            E0_uncertain\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    likelihood_model = pm.Normal(\n",
    "        \"likelihood_model\",\n",
    "        mu=fitting_model,\n",
    "        sigma=standard_deviation,\n",
    "        observed=observations_to_fit\n",
    "    )\n",
    "\n",
    "    seirdpq_trace_calibration = pm.sample_smc(\n",
    "        draws=draws,\n",
    "        n_steps=25,\n",
    "        parallel=True,\n",
    "        cores=8,\n",
    "        progressbar=True,\n",
    "        random_seed=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for posterior calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rv_posterior_mpv(pm_trace, variable_names: list) -> dict:\n",
    "    rv_mpv_values_dict = dict()\n",
    "    progress_bar = tqdm(variable_names)\n",
    "    for variable in progress_bar:\n",
    "        progress_bar.set_description(f\"Calulating MPV from KDE for {variable}\")\n",
    "        rv_realization_values = pm_trace[f\"{variable}\"]\n",
    "\n",
    "        try:\n",
    "            num_of_dimensions = rv_realization_values.shape[1]\n",
    "        except IndexError:\n",
    "            num_of_dimensions = 0\n",
    "\n",
    "        if num_of_dimensions == 0:\n",
    "            rv_mpv_value = _scalar_rv_mvp_estimation(rv_realization_values)\n",
    "            rv_mpv_values_dict[f\"{variable}\"] = rv_mpv_value\n",
    "        else:\n",
    "            for dimension in range(num_of_dimensions):\n",
    "                variable_name_decomposed = f\"{variable}[{dimension}]\"\n",
    "                rv_realization_values_decomposed = np.array(rv_realization_values[:, dimension])\n",
    "                rv_mpv_value = _scalar_rv_mvp_estimation(rv_realization_values_decomposed)\n",
    "                rv_mpv_values_dict[f\"{variable_name_decomposed}\"] = rv_mpv_value\n",
    "\n",
    "    return rv_mpv_values_dict\n",
    "\n",
    "\n",
    "def _scalar_rv_mvp_estimation(rv_realization_values: np.ndarray) -> np.ndarray:\n",
    "    num_of_realizations = len(rv_realization_values)\n",
    "    kernel = gaussian_kde(rv_realization_values)\n",
    "    equally_spaced_samples = np.linspace(\n",
    "        rv_realization_values.min(),\n",
    "        rv_realization_values.max(),\n",
    "        num_of_realizations\n",
    "    )\n",
    "    kde = kernel(equally_spaced_samples)\n",
    "    kde_max_index = np.argmax(kde)\n",
    "    rv_mpv_value = equally_spaced_samples[kde_max_index]\n",
    "    return rv_mpv_value\n",
    "\n",
    "\n",
    "def add_mpv_to_summary(arviz_summary: pd.DataFrame, rv_modes_dict: dict) -> pd.DataFrame:\n",
    "    new_arviz_summary = arviz_summary.copy()\n",
    "    variable_names = list(rv_modes_dict.keys())\n",
    "    rv_mode_values = list(rv_modes_dict.values())\n",
    "    new_arviz_summary[\"mpv\"] = pd.Series(data=rv_mode_values, index=variable_names)\n",
    "    return new_arviz_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calibration_variable_names = [\n",
    "    \"std_deviation\",\n",
    "    \"beta\",\n",
    "    \"omega\",\n",
    "    \"d_P\",\n",
    "    \"E0\"\n",
    "]\n",
    "\n",
    "plot_step = 1\n",
    "\n",
    "progress_bar = tqdm(calibration_variable_names)\n",
    "for variable in progress_bar:\n",
    "    progress_bar.set_description(\"Arviz post-processing\")\n",
    "    pm.traceplot(seirdpq_trace_calibration[::plot_step], var_names=(f\"{variable}\"))\n",
    "    plt.savefig(f\"{OUTPUT_PATH}/seirpdq_{variable}_traceplot_cal_{bayes_data_fit}_{num_data_calibration}.pdf\")\n",
    "\n",
    "    pm.plot_posterior(\n",
    "        seirdpq_trace_calibration[::plot_step], \n",
    "        var_names=(f\"{variable}\"), \n",
    "        kind=\"hist\", \n",
    "        round_to=5,\n",
    "        point_estimate=\"mode\"\n",
    "    )\n",
    "    plt.savefig(f\"{OUTPUT_PATH}/seirpdq_{variable}_posterior_cal_{bayes_data_fit}_{num_data_calibration}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_summary = az.summary(\n",
    "    data=seirdpq_trace_calibration,\n",
    "    var_names=calibration_variable_names,\n",
    "    kind='stats',\n",
    "    round_to=15,\n",
    ")\n",
    "calibration_variable_modes = calculate_rv_posterior_mpv(\n",
    "    pm_trace=seirdpq_trace_calibration, variable_names=calibration_variable_names\n",
    ")\n",
    "df_stats_summary = add_mpv_to_summary(df_stats_summary, calibration_variable_modes)\n",
    "df_stats_summary.to_csv(f\"{OUTPUT_PATH}/stats_summary_calibration_{bayes_data_fit}_{num_data_calibration}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(\n",
    "    seirdpq_trace_calibration,\n",
    "    var_names=calibration_variable_names[1:],\n",
    "    kind=\"hexbin\",\n",
    "    fill_last=False,\n",
    "    figsize=(10, 8),\n",
    ")\n",
    "plt.savefig(f\"{OUTPUT_PATH}/seirpdq_marginals_cal_{bayes_data_fit}_{num_data_calibration}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Bayesian calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_cut = 2.5\n",
    "\n",
    "y_min = np.percentile(seirdpq_trace_calibration[\"seirpdq_model\"], percentile_cut, axis=0)\n",
    "y_max = np.percentile(seirdpq_trace_calibration[\"seirpdq_model\"], 100 - percentile_cut, axis=0)\n",
    "y_fit = np.percentile(seirdpq_trace_calibration[\"seirpdq_model\"], 50, axis=0)\n",
    "\n",
    "std_deviation = seirdpq_trace_calibration.get_values(\"std_deviation\")\n",
    "sd_pop = np.sqrt(std_deviation.mean())\n",
    "\n",
    "data_time_calibration = data_time[0 : num_data_calibration]\n",
    "calibration_data = (observations_to_fit).T\n",
    "\n",
    "data_time_validation = data_time[num_data_calibration : (num_data_calibration + num_days_prediction)]\n",
    "validation_data = np_original_data[:, num_data_calibration : (num_data_calibration + num_days_prediction)]\n",
    "\n",
    "# %%\n",
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "plt.plot(\n",
    "    data_time_calibration,\n",
    "    y_fit[:, 0],\n",
    "    \"r\",\n",
    "    label=\"Deaths (SEIRPD-Q)\",\n",
    "    marker=\"D\",\n",
    "    linestyle=\"-\",\n",
    "    markersize=2,\n",
    ")\n",
    "plt.fill_between(data_time_calibration, y_min[:, 0], y_max[:, 0], color=\"r\", alpha=0.2)\n",
    "\n",
    "plt.plot(\n",
    "    data_time_calibration,\n",
    "    y_fit[:, 1],\n",
    "    \"b\",\n",
    "    label=\"Cases (SEIRPD-Q)\",\n",
    "    marker=\"v\",\n",
    "    linestyle=\"-\",\n",
    "    markersize=2,\n",
    ")\n",
    "plt.fill_between(data_time_calibration, y_min[:, 1], y_max[:, 1], color=\"b\", alpha=0.2)\n",
    "\n",
    "plt.plot(\n",
    "    data_time_calibration, calibration_data[1, :], label=\"Confirmed data\", marker=\"s\", linestyle=\"\", markersize=2\n",
    ")\n",
    "plt.plot(\n",
    "    data_time_calibration, calibration_data[0, :], label=\"Recorded deaths\", marker=\"v\", linestyle=\"\", markersize=2\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"{OUTPUT_PATH}/seirpdq_calibration_bayes_{bayes_data_fit}_{num_data_calibration}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_realizations = dict()\n",
    "progress_bar = tqdm(calibration_variable_names[1:])\n",
    "for variable in progress_bar:\n",
    "    progress_bar.set_description(f\"Gathering {variable} realizations\")\n",
    "    parameter_realization = seirdpq_trace_calibration.get_values(f\"{variable}\")\n",
    "    dict_realizations[f\"{variable}\"] = parameter_realization\n",
    "\n",
    "df_realizations = pd.DataFrame(dict_realizations)\n",
    "df_realizations.to_csv(f\"{OUTPUT_PATH}/calibration_realizations_{bayes_data_fit}_{num_data_calibration}.csv\")\n",
    "\n",
    "S_predicted = list()\n",
    "E_predicted = list()\n",
    "I_predicted = list()\n",
    "P_predicted = list()\n",
    "R_predicted = list()\n",
    "D_predicted = list()\n",
    "C_predicted = list()\n",
    "H_predicted = list()\n",
    "\n",
    "data_time_prediction = np.hstack([data_time_calibration, data_time_validation])\n",
    "t0 = np.min(data_time_prediction)\n",
    "tf = np.max(data_time_prediction)\n",
    "\n",
    "number_of_total_realizations = len(dict_realizations[\"beta\"])\n",
    "for realization in trange(number_of_total_realizations):\n",
    "    parameters_realization = [\n",
    "        realization_reg[realization, 0],\n",
    "        realization_reg[realization, 1],\n",
    "        realization_reg[realization, 2],\n",
    "    ]\n",
    "    y0_estimated = (\n",
    "        target_population - (realization_reg[realization, 3] + I0 + P0 + R0 + D0),\n",
    "        realization_reg[realization, 3],\n",
    "        I0,\n",
    "        P0,\n",
    "        R0,\n",
    "        D0,\n",
    "        C0,\n",
    "        H0,\n",
    "    )\n",
    "    solution_ODE_predict = seirpdq_ode_solver(\n",
    "        y0_estimated, (t0, tf), data_time_prediction, *parameters_realization\n",
    "    )\n",
    "    t_computed_predict, y_computed_predict = solution_ODE_predict.t, solution_ODE_predict.y\n",
    "    S, E, I, P, R, D, C, H = y_computed_predict\n",
    "\n",
    "    S_predicted.append(S)\n",
    "    E_predicted.append(E)\n",
    "    I_predicted.append(I)\n",
    "    P_predicted.append(P)\n",
    "    R_predicted.append(R)\n",
    "    D_predicted.append(D)\n",
    "    C_predicted.append(C)\n",
    "    H_predicted.append(H)\n",
    "\n",
    "S_predicted = np.array(S_predicted)\n",
    "E_predicted = np.array(E_predicted)\n",
    "I_predicted = np.array(I_predicted)\n",
    "P_predicted = np.array(P_predicted)\n",
    "R_predicted = np.array(R_predicted)\n",
    "D_predicted = np.array(D_predicted)\n",
    "C_predicted = np.array(C_predicted)\n",
    "H_predicted = np.array(H_predicted)\n",
    "\n",
    "percentile_cut = 2.5\n",
    "S_min = np.percentile(S_predicted, percentile_cut, axis=0)\n",
    "S_max = np.percentile(S_predicted, 100 - percentile_cut, axis=0)\n",
    "S_mean = np.percentile(S_predicted, 50, axis=0)\n",
    "\n",
    "E_min = np.percentile(E_predicted, percentile_cut, axis=0)\n",
    "E_max = np.percentile(E_predicted, 100 - percentile_cut, axis=0)\n",
    "E_mean = np.percentile(E_predicted, 50, axis=0)\n",
    "\n",
    "I_min = np.percentile(I_predicted, percentile_cut, axis=0)\n",
    "I_max = np.percentile(I_predicted, 100 - percentile_cut, axis=0)\n",
    "I_mean = np.percentile(I_predicted, 50, axis=0)\n",
    "\n",
    "P_min = np.percentile(P_predicted, percentile_cut, axis=0)\n",
    "P_max = np.percentile(P_predicted, 100 - percentile_cut, axis=0)\n",
    "P_mean = np.percentile(P_predicted, 50, axis=0)\n",
    "\n",
    "R_min = np.percentile(R_predicted, percentile_cut, axis=0)\n",
    "R_max = np.percentile(R_predicted, 100 - percentile_cut, axis=0)\n",
    "R_mean = np.percentile(R_predicted, 50, axis=0)\n",
    "\n",
    "D_min = np.percentile(D_predicted, percentile_cut, axis=0)\n",
    "D_max = np.percentile(D_predicted, 100 - percentile_cut, axis=0)\n",
    "D_mean = np.percentile(D_predicted, 50, axis=0)\n",
    "\n",
    "C_min = np.percentile(C_predicted, percentile_cut, axis=0)\n",
    "C_max = np.percentile(C_predicted, 100 - percentile_cut, axis=0)\n",
    "C_mean = np.percentile(C_predicted, 50, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Bayesian prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "ax1.plot(\n",
    "    t_computed_predict,\n",
    "    C_mean,\n",
    "    \"r\",\n",
    "    label=\"Confirmed cases\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    markersize=0,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax1.fill_between(t_computed_predict, C_min, C_max, color=\"r\", alpha=0.2)\n",
    "\n",
    "ax1.plot(\n",
    "    data_time_calibration, calibration_data[1, :], label=\"Confirmed data (calibration)\", marker=\"o\", linestyle=\"\", markersize=3, color='C1'\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    data_time_validation, validation_data[2, :], label=\"Confirmed data (validation)\", marker=\"o\", linestyle=\"\", markersize=6\n",
    ")\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "\n",
    "ax2.plot(\n",
    "    t_computed_predict,\n",
    "    I_mean,\n",
    "    \"g\",\n",
    "    label=\"Infected\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    markersize=0,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax2.fill_between(t_computed_predict, I_min, I_max, color=\"c\", alpha=0.2)\n",
    "\n",
    "ax2.plot(\n",
    "    t_computed_predict,\n",
    "    P_mean,\n",
    "    \"b\",\n",
    "    label=\"Positively diagnosed\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    markersize=0,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax2.fill_between(t_computed_predict, P_min, P_max, color=\"b\", alpha=0.2)\n",
    "\n",
    "ax1.plot(\n",
    "    t_computed_predict,\n",
    "    D_mean,\n",
    "    \"k\",\n",
    "    label=\"Dead individuals\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"-\",\n",
    "    markersize=0,\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax1.fill_between(t_computed_predict, D_min, D_max, color=\"k\", alpha=0.2)\n",
    "\n",
    "ax1.plot(\n",
    "    data_time_calibration, calibration_data[0, :], label=\"Recorded deaths (calibration)\", marker=\"o\", linestyle=\"\", markersize=3\n",
    ")\n",
    "\n",
    "ax2.plot(\n",
    "    data_time_validation, validation_data[0, :], label=\"Recorded deaths (validation)\", marker=\"o\", linestyle=\"\", markersize=6\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Population\")\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "ax1.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"{OUTPUT_PATH}/seirpdq_prediction_cumulative_{bayes_data_fit}_{num_data_calibration}_scaled.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
